{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the severity of service disruption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import data from csv into pandas dataFrame\n",
    "import pandas as pd\n",
    "severity_type = pd.read_csv('/Users/sumantbhandari/Desktop/Data Analysis/severity_type.csv', header=0)\n",
    "log_feature = pd.read_csv('/Users/sumantbhandari/Desktop/Data Analysis/log_feature.csv', header=0)\n",
    "train = pd.read_csv('/Users/sumantbhandari/Desktop/Data Analysis/train.csv', header=0)\n",
    "test = pd.read_csv('/Users/sumantbhandari/Desktop/Data Analysis/test.csv', header=0)\n",
    "event_type = pd.read_csv('/Users/sumantbhandari/Desktop/Data Analysis/event_type.csv', header=0)\n",
    "resource_type = pd.read_csv('/Users/sumantbhandari/Desktop/Data Analysis/resource_type.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert categorical variables into indicator variables\n",
    "severity_type_dummies = pd.get_dummies(severity_type)\n",
    "log_feature_dummies= pd.get_dummies(log_feature)\n",
    "event_type_dummies = pd.get_dummies(event_type)\n",
    "resource_type_dummies = pd.get_dummies(resource_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Aggregate duplicate entries of id and collapse rows with their sum\n",
    "event_type_dummies= event_type_dummies.groupby(event_type_dummies.id).sum()\n",
    "resource_type_dummies = resource_type_dummies.groupby(resource_type_dummies.id).sum()\n",
    "severity_type_dummies = severity_type_dummies.groupby(severity_type_dummies.id).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use Volume as weights, and multiply it with every other columns in the log_feature data.\n",
    "\n",
    "# take all columns except volume\n",
    "columns = log_feature_dummies.columns[2:]\n",
    "# Multiply all columns of log_dummy with vol\n",
    "log_feature_dummies_mulVol = log_feature_dummies[columns].multiply(log_feature_dummies[\"volume\"], axis='index')\n",
    "# add id column to log_dummy\n",
    "log_feature_dummies_mulVol[\"id\"]  = log_feature_dummies.id\n",
    "# aggregate by id and summ up all rows\n",
    "log_feature_dummies_mulVol = log_feature_dummies_mulVol.groupby(log_feature_dummies_mulVol.id).sum()\n",
    "\n",
    "# Add feature -  AggregateVol\n",
    "# aggregate by id and caluclate total sum of volume for that time id\n",
    "Df_withAggVol = log_feature.groupby(log_feature.id).sum()\n",
    "Df_withAggVol.columns = [\"AggregateVol\"]\n",
    "\n",
    "# Add column AggregateVol to the log_feature_dummies_sumVol datframe\n",
    "log_feature_dummies_sumVol = pd.concat([log_feature_dummies_mulVol,Df_withAggVol], axis=1, join =\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge test and train with severtity_type and extract time sequence\n",
    "trainPlusTestDF_Sev = pd.concat([train,test], axis=0)\n",
    "merged_SevTestdf = pd.merge(severity_type,trainPlusTestDF_Sev, on='id')\n",
    "merged_SevTestdf['time_seq'] = merged_SevTestdf.groupby('location').cumcount()\n",
    "merged_SevTestdf = merged_SevTestdf.set_index(\"id\")\n",
    "time_seq = merged_SevTestdf.time_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>severity_type</th>\n",
       "      <th>fault_severity</th>\n",
       "      <th>location</th>\n",
       "      <th>time_seq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6597</th>\n",
       "      <td>severity_type 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8011</th>\n",
       "      <td>severity_type 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>location 1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>severity_type 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5022</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6852</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5611</th>\n",
       "      <td>severity_type 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14838</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>location 1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4848</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>location 1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6914</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>location 1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5337</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>location 1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10460</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15494</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>location 1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10289</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8587</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12943</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>severity_type 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16416</th>\n",
       "      <td>severity_type 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9446</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12482</th>\n",
       "      <td>severity_type 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16538</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2250</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>location 1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5259</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>location 1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12751</th>\n",
       "      <td>severity_type 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5195</th>\n",
       "      <td>severity_type 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4703</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>location 1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17508</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11382</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>location 998</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8390</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>location 998</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8972</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>location 998</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14027</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 998</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14916</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>location 998</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 998</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18243</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 998</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10868</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 998</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13670</th>\n",
       "      <td>severity_type 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>location 998</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10241</th>\n",
       "      <td>severity_type 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 998</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>severity_type 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 998</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12775</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 998</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15227</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 998</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16843</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 998</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9423</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9563</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4196</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>location 999</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10096</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 999</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6288</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>location 999</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13296</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>location 999</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 999</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15206</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 999</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15084</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 999</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8114</th>\n",
       "      <td>severity_type 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>location 999</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8955</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 999</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3761</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 999</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8720</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 999</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6488</th>\n",
       "      <td>severity_type 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location 999</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>severity_type 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>location 999</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4464</th>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>location 999</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18552 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         severity_type  fault_severity      location  time_seq\n",
       "id                                                            \n",
       "6597   severity_type 2             NaN    location 1         0\n",
       "8011   severity_type 2             0.0    location 1         1\n",
       "2597   severity_type 2             NaN    location 1         2\n",
       "5022   severity_type 1             NaN    location 1         3\n",
       "6852   severity_type 1             NaN    location 1         4\n",
       "5611   severity_type 2             NaN    location 1         5\n",
       "14838  severity_type 1             NaN    location 1         6\n",
       "2588   severity_type 1             0.0    location 1         7\n",
       "4848   severity_type 1             0.0    location 1         8\n",
       "6914   severity_type 1             0.0    location 1         9\n",
       "5337   severity_type 1             0.0    location 1        10\n",
       "10460  severity_type 1             NaN    location 1        11\n",
       "15494  severity_type 1             0.0    location 1        12\n",
       "10289  severity_type 1             NaN    location 1        13\n",
       "8587   severity_type 1             NaN    location 1        14\n",
       "12943  severity_type 1             NaN    location 1        15\n",
       "590    severity_type 2             NaN    location 1        16\n",
       "16416  severity_type 2             NaN    location 1        17\n",
       "3399   severity_type 1             NaN    location 1        18\n",
       "1505   severity_type 1             NaN    location 1        19\n",
       "9446   severity_type 1             NaN    location 1        20\n",
       "12482  severity_type 2             NaN    location 1        21\n",
       "16538  severity_type 1             NaN    location 1        22\n",
       "2250   severity_type 1             0.0    location 1        23\n",
       "5259   severity_type 1             0.0    location 1        24\n",
       "12751  severity_type 2             NaN    location 1        25\n",
       "5195   severity_type 2             NaN    location 1        26\n",
       "1233   severity_type 1             NaN    location 1        27\n",
       "4703   severity_type 1             2.0    location 1        28\n",
       "17508  severity_type 1             NaN    location 1        29\n",
       "...                ...             ...           ...       ...\n",
       "11382  severity_type 1             1.0  location 998        12\n",
       "8390   severity_type 1             1.0  location 998        13\n",
       "8972   severity_type 1             0.0  location 998        14\n",
       "14027  severity_type 1             NaN  location 998        15\n",
       "14916  severity_type 1             1.0  location 998        16\n",
       "359    severity_type 1             NaN  location 998        17\n",
       "18243  severity_type 1             NaN  location 998        18\n",
       "10868  severity_type 1             NaN  location 998        19\n",
       "13670  severity_type 2             0.0  location 998        20\n",
       "10241  severity_type 4             NaN  location 998        21\n",
       "153    severity_type 4             NaN  location 998        22\n",
       "12775  severity_type 1             NaN  location 998        23\n",
       "15227  severity_type 1             NaN  location 998        24\n",
       "16843  severity_type 1             NaN  location 998        25\n",
       "9423   severity_type 1             NaN  location 999         0\n",
       "9563   severity_type 1             NaN  location 999         1\n",
       "4196   severity_type 1             1.0  location 999         2\n",
       "10096  severity_type 1             NaN  location 999         3\n",
       "6288   severity_type 1             1.0  location 999         4\n",
       "13296  severity_type 1             1.0  location 999         5\n",
       "1989   severity_type 1             NaN  location 999         6\n",
       "15206  severity_type 1             NaN  location 999         7\n",
       "15084  severity_type 1             NaN  location 999         8\n",
       "8114   severity_type 2             0.0  location 999         9\n",
       "8955   severity_type 1             NaN  location 999        10\n",
       "3761   severity_type 1             NaN  location 999        11\n",
       "8720   severity_type 1             NaN  location 999        12\n",
       "6488   severity_type 2             NaN  location 999        13\n",
       "878    severity_type 2             0.0  location 999        14\n",
       "4464   severity_type 1             0.0  location 999        15\n",
       "\n",
       "[18552 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_SevTestdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add another feature : total vol per location from merging test and train with the log_table \n",
    "# for each location get the total count and map it with id\n",
    "trainPlusTestDF = pd.concat([train,test], axis=0)\n",
    "merged_LogTestdf = pd.merge(log_feature,trainPlusTestDF, on='id')\n",
    "grouped_LogTestdf = merged_LogTestdf.groupby(merged_LogTestdf.location).mean()\n",
    "grouped_LogTestdf = grouped_LogTestdf.drop(['id','fault_severity'], axis=1 )\n",
    "grouped_LogTestdf.columns = [\"volume_per_location\"]\n",
    "grouped_LogTestdf['location'] = grouped_LogTestdf.index\n",
    "volume_per_location_df = pd.merge(grouped_LogTestdf,merged_LogTestdf, on='location')\n",
    "volume_per_location_df = volume_per_location_df.groupby(volume_per_location_df.id).sum()\n",
    "volume_per_location = volume_per_location_df[\"volume_per_location\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Join the created features with the log_feature_dummies_sumVol dataframe\n",
    "log_feature_dummies_sumVol = pd.concat([log_feature_dummies_sumVol,time_seq], axis=1, join =\"inner\")\n",
    "log_feature_dummies_sumVol = pd.concat([log_feature_dummies_sumVol,volume_per_location], axis=1, join =\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge all the dataframes together on id\n",
    "mergedAttributes_df = pd.concat([log_feature_dummies_sumVol, event_type_dummies,resource_type_dummies, severity_type_dummies], axis=1)\n",
    "train = train.set_index(\"id\")\n",
    "test = test.set_index(\"id\")\n",
    "finaltrain_df = pd.concat([mergedAttributes_df, train], axis=1, join =\"inner\")\n",
    "finaltest_df = pd.concat([mergedAttributes_df, test], axis=1, join =\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7381, 459)\n",
      "(11171, 458)\n"
     ]
    }
   ],
   "source": [
    "print(finaltrain_df.shape)\n",
    "print(finaltest_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for any null values\n",
    "finaltest_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# store labels in Y_train\n",
    "Y_train= finaltrain_df.pop('fault_severity')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# Convert location as discrete numeric variable.\n",
    "finaltrain_df['location_id'] = finaltrain_df['location'].str[8:].astype(float)\n",
    "finaltrain_df['location_id'].describe()\n",
    "finaltrain_df.pop('location')\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=8,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='multi:softprob', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGBoost\n",
    "import xgboost as xg\n",
    "clf = xg.XGBClassifier(max_depth=8)\n",
    "clf.fit(finaltrain_df, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict_0</th>\n",
       "      <th>predict_1</th>\n",
       "      <th>predict_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11066</th>\n",
       "      <td>0.983432</td>\n",
       "      <td>0.015949</td>\n",
       "      <td>0.000618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18000</th>\n",
       "      <td>0.086721</td>\n",
       "      <td>0.139683</td>\n",
       "      <td>0.773596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16964</th>\n",
       "      <td>0.989321</td>\n",
       "      <td>0.010137</td>\n",
       "      <td>0.000542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>0.942497</td>\n",
       "      <td>0.054193</td>\n",
       "      <td>0.003310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3392</th>\n",
       "      <td>0.380555</td>\n",
       "      <td>0.594000</td>\n",
       "      <td>0.025445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       predict_0  predict_1  predict_2\n",
       "id                                    \n",
       "11066   0.983432   0.015949   0.000618\n",
       "18000   0.086721   0.139683   0.773596\n",
       "16964   0.989321   0.010137   0.000542\n",
       "4795    0.942497   0.054193   0.003310\n",
       "3392    0.380555   0.594000   0.025445"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate probabilities for test set\n",
    "finaltest_df['location_id'] = finaltest_df['location'].str[8:].astype(float)\n",
    "finaltest_df.pop('location')\n",
    "a = clf.predict_proba(finaltest_df)\n",
    "finaltestsubmit_df = pd.DataFrame(a)\n",
    "finaltestsubmit_df[\"id\"] = finaltest_df.index\n",
    "finaltestsubmit_df = finaltestsubmit_df.set_index(\"id\")\n",
    "finaltestsubmit_df.columns =[\"predict_0\", \"predict_1\", \"predict_2\"]\n",
    "finaltestsubmit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate csv\n",
    "finaltestsubmit_df.to_csv(\"final_submission\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below is the code used for tuning parameters and experimenting other algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sumantbhandari/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Create validation set \n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(finaltrain_df, Y_train, test_size=0.25, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize - did not improve output for Tree based models. \n",
    "#location = finaltrain_df.location\n",
    "#import numpy as np\n",
    "#Normalized_df = finaltrain_df.ix[:, finaltrain_df.columns != \"location\"].apply(lambda x: ((x - np.min(x)) / (np.max(x) - np.min(x)))\\\n",
    "#                                                                               if np.max(x) != 0 else 0)\n",
    "#Normalized_df['location'] = location\n",
    "#finaltrain_df = Normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1083   83   17]\n",
      " [ 342  122   13]\n",
      " [  73   14   99]]\n",
      "0.70639219935\n"
     ]
    }
   ],
   "source": [
    "import sklearn.linear_model as l\n",
    "import numpy as np\n",
    "\n",
    "clf = l.LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "a=clf.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(list(np.array(y_test)), list(a)))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(list(np.array(y_test)), list(a)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1063  108   12]\n",
      " [ 217  236   24]\n",
      " [  37   36  113]]\n",
      "0.764897074756\n"
     ]
    }
   ],
   "source": [
    "#for validation purpose\n",
    "#RandomForest\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=30)\n",
    "clf.fit(X_train, y_train)\n",
    "a=clf.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(list(np.array(y_test)), list(a)))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(list(np.array(y_test)), list(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1073  100   10]\n",
      " [ 180  271   26]\n",
      " [  30   23  133]]\n",
      "0.800108342362\n"
     ]
    }
   ],
   "source": [
    "#Validation\n",
    "#xgboost\n",
    "import xgboost as xg\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "clf = xg.XGBClassifier(max_depth=9)\n",
    "clf.fit(X_train, y_train)\n",
    "#pyplot.bar(range(len(clf.feature_importances_)), clf.feature_importances_)\n",
    "#pyplot.show()\n",
    "a=clf.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(list(np.array(y_test)), list(a)))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(list(np.array(y_test)), list(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.80974949  0.79403794  0.78794038  0.79674797  0.79200542]\n"
     ]
    }
   ],
   "source": [
    "#Validation - this one with cross validation\n",
    "#RandomForest\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "import numpy as np\n",
    "k_fold = KFold(len(finaltrain_df), n_folds=5, shuffle=True, random_state=0)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=30)\n",
    "clf.fit(finaltrain_df, Y_train)\n",
    "print(cross_val_score(clf, finaltrain_df, Y_train, cv=k_fold, n_jobs=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.81719702  0.81300813  0.79878049  0.8096206   0.79945799]\n"
     ]
    }
   ],
   "source": [
    "#Validation - this one with cross validation\n",
    "#xgboost\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "import xgboost as xg\n",
    "import numpy as np\n",
    "k_fold = KFold(len(finaltrain_df), n_folds=5, shuffle=True, random_state=0)\n",
    "clf = xg.XGBClassifier(max_depth=8)\n",
    "clf.fit(finaltrain_df, Y_train)\n",
    "print(cross_val_score(clf, finaltrain_df, Y_train, cv=k_fold, n_jobs=1))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
